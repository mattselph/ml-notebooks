{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-ML Overview & Preprocessing",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattselph/ml-notebooks/blob/master/1_ML_Overview_%26_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vWlqVc1s_vg",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning Overview\n",
        "Normally, you write a program and give it rules to follow to arrive at a certain output.  \n",
        "\n",
        "With Machine Learning (ML), you have the output and the computer determines the rules.\n",
        "\n",
        "# Types of Machine Learning\n",
        "There are three types of ML:\n",
        "\n",
        "\n",
        "1.   Supervised Learning\n",
        "2.   Unsupervised Learning\n",
        "3.   Reinforcement Learning\n",
        "\n",
        "## Supervised Learning\n",
        "Supervised learning has labeled data and a known outcome.  It's up to the ML algorithm to figure out what rules are inherent in the data. You train it on some data then test the produced **model** against unseen data and use statistics to determine the confidence in your model.  Then, you repeat, **supervising** the training and testing of the algorithm.\n",
        "\n",
        "*Example:  Medical data about patients and whether or not they have heart disease.  It's up to the ML algorithm to determine what pieces of data are important when predicting whether someone has heart disease or not.*\n",
        "\n",
        "## Unsupervised Learning\n",
        "Unsupervised learning has unlabeled data.  \n",
        "\n",
        "*Example:  Credit card companies use unsupervised learning to detect fraudulent or suspicious credit card transactions.*\n",
        "\n",
        "## Reinforcement Learning\n",
        "This is when an algorithm is trained by trial and error.\n",
        "\n",
        "*Example:  Computer software to play chess against someone.*\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQH-tl8pw1Fp",
        "colab_type": "text"
      },
      "source": [
        "# Common ML Algorithms\n",
        "There are several common ML algorithms, which makes ML a large field.  There are probably more, but these are the ones I'm most familiar with:\n",
        "\n",
        "\n",
        "1.   Regression (Linear & Logistic)\n",
        "2.   Nearest Neighbor (Abbreviated *K*-Nearest Neighbor or KNN)\n",
        "3.   Random Forest\n",
        "4.   Naive Bayes\n",
        "5.   Support Vector Machines (SVM)\n",
        "6.   Neural Networks\n",
        "\n",
        "There are separate notebooks for each of those algorithms.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szKeoO1HxAwg",
        "colab_type": "text"
      },
      "source": [
        "# Common Software Libraries\n",
        "There are many software libraries used throughout the ML process.  ML code is surprisingly simple.  The libraries do all the heavy lifting.\n",
        "\n",
        "*   [scikit-learn](https://scikit-learn.org/stable/) - Used for most everything except Neural Networks.  There's lots of good packages in scikit-learn to handle the early steps in a ML workflow, like preprocessing and making a training/test data set.  \n",
        "*   [Tensorflow](https://www.tensorflow.org/) - Most popular ML library.  Developed by Google.  Use version 2.0.\n",
        "*   [Keras](https://keras.io/) - Keras is an API specification on top of Tensorflow and other popular ML libraries such as PyTorch.  For neural networks, I've found it's easier to just use Keras since it has sensible defaults and works right out of the box.  It uses the Tensorflow backend by default, too, so you're really using Tensorflow.  Just a more convenient API.  In Tensorflow 2.0, Keras is tightly integrated, so you might not need the high-level Keras library if you're doing Tensorflow in the future.\n",
        "*   [PyTorch](https://pytorch.org/) - I don't use this one or know anything about it.\n",
        "\n",
        "There are also libraries used in the preprocessing and data cleaning stages of ML that you'll work with.  These libraries are dependencies of the common libraries above.  But you'll work with them independently, as well.\n",
        "\n",
        "*   [Numpy](https://www.numpy.org/) - Used for scientific processing.  In ML, numpy is mostly used under the hood for matrix multiplication.\n",
        "*   [Pandas](https://pandas.pydata.org/) - Used to view data in tables (called DataFrames) and manipulate it.  A lot of ML functions take a Pandas DataFrame as input.  \n",
        "*   [matplotlib](https://matplotlib.org) - Used to graph stuff.  You can usually provide a Pandas DataFrame as input and you get a graph of the data.\n",
        "*   [seaborn](https://seaborn.pydata.org/) - Based on matplotlib, but focused on specific types of graphs usually found in statistical analysis, like histograms, scatter plots, and pair plots.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JSIIllIhqOp",
        "colab_type": "text"
      },
      "source": [
        "# Terminology\n",
        "\n",
        "*   Features - columns of a dataset you're going to use in your predictions.  \n",
        "*   Target - the data you're trying to predict.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGsRuTutgFN0",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning Workflow\n",
        "Three basic steps:\n",
        "\n",
        "1.   Preprocessing - Preparing the data to be inputted into a ML model for training.  Makes heavy use of Pandas and ```sklearn.preprocessing```.  You split the data into a train set and a test set, usually at a ratio of 80/20.  That way you can train your model and test it against data it hasn't seen yet.  This improves accuracy.\n",
        "2.   Train the model - Process the data.  This is the stage in which the computer learns.\n",
        "3.   Predict - The final step, where predictions are made.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALJkIG55kwky",
        "colab_type": "text"
      },
      "source": [
        "# Next Steps\n",
        "Go to the next notebook, ```2-ML Linear Regression``` for the first ML algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWlJwjGnyMU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}